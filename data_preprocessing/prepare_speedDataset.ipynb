{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syllables\n",
    "import re\n",
    "from IPython.display import Audio\n",
    "def play_audio(audio_path):\n",
    " \n",
    "    audio = Audio(audio_path)\n",
    "    display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import webrtcvad\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def get_speech_length(wav_path):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_wav(wav_path)\n",
    "    # Convert the audio to 16-bit PCM format with a sample rate of 16000 Hz\n",
    "    audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)\n",
    "    # Get the raw audio data\n",
    "    raw_audio = audio.raw_data\n",
    "    # Initialize the VAD object\n",
    "    vad = webrtcvad.Vad()\n",
    "    # Set the aggressiveness level of the VAD (1, 2, or 3, where 3 is the most aggressive)\n",
    "    vad.set_mode(3)\n",
    "    frame_duration = 30  # in milliseconds\n",
    "    frame_length = int(audio.frame_rate * (frame_duration / 1000)) * audio.sample_width\n",
    "    speech_length = 0\n",
    "    for i in range(0, len(raw_audio), frame_length):\n",
    "        frame = raw_audio[i:i + frame_length]\n",
    "        if len(frame) == frame_length:\n",
    "            if vad.is_speech(frame, audio.frame_rate):\n",
    "                speech_length += frame_duration / 1000\n",
    "\n",
    "    return speech_length\n",
    "\n",
    "def count_tokens_in_transcript(transcript, tokenizer,use_tokenizer=False):\n",
    "    \n",
    "        # Open the text file and read the first line\n",
    "\n",
    "    # Tokenize the transcript\n",
    "    # tokens = tokenizer.tokenize(transcript)\n",
    "    if use_tokenizer:\n",
    "            \n",
    "        tokens = tokenizer.encode_plus(\n",
    "            transcript,\n",
    "            add_special_tokens=False,\n",
    "            return_tensors='np'\n",
    "        )['input_ids'][0]\n",
    "        # print (transcript)\n",
    "        # print (tokens)\n",
    "        # Count the number of tokens\n",
    "        token_count = len(tokens)\n",
    "        return token_count\n",
    "    else:\n",
    "        # print (transcript)\n",
    "        transcript = transcript.replace(\" \", \"\")\n",
    "        return len(transcript )\n",
    "def remove_non_word_text(transcript):\n",
    "    # The regular expression pattern [^a-zA-Z\\s] matches any character that is not\n",
    "    # an alphabetic character (either uppercase or lowercase) or a whitespace character.\n",
    "    processed_text = re.sub('[^a-zA-Z\\s]', '', transcript)\n",
    "    # Optionally, you can also collapse multiple consecutive spaces into a single space\n",
    "    processed_text = re.sub('\\s+',' ', processed_text).strip()\n",
    "    return processed_text\n",
    "def count_syllables_in_transcript(transcript):\n",
    "    # Count the number of syllables\n",
    "    syllable_count = 0 \n",
    "    transcript = remove_non_word_text(transcript)\n",
    "    for word in transcript.split():\n",
    "        syllable_count += syllables.estimate(word)\n",
    "    return syllable_count\n",
    "      \n",
    "\n",
    "def calculate_token_ratios(path_list, tokenizer, use_tokenizer=False):\n",
    "    ratios = []\n",
    "    log = {}\n",
    "    for wav_path, text_caption in tqdm(path_list):\n",
    "        speech_length = get_speech_length(wav_path)\n",
    "        token_count = count_tokens_in_transcript(text_caption, tokenizer, use_tokenizer)\n",
    "        if speech_length and token_count:\n",
    "            ratio = speech_length / token_count\n",
    "            ratios.append(ratio)\n",
    "            log[os.path.basename(wav_path)] = ratio\n",
    "    return ratios, log\n",
    "\n",
    "def calculate_syllable_ratios(path_list):\n",
    "    ratios = []\n",
    "    log = {}\n",
    "    for wav_path, text_caption in tqdm(path_list):\n",
    "        speech_length = get_speech_length(wav_path)\n",
    "        syllable_count = count_syllables_in_transcript(text_caption)\n",
    "        if speech_length and syllable_count:\n",
    "            ratio = speech_length / syllable_count\n",
    "            ratios.append(ratio)\n",
    "            log[os.path.basename(wav_path)] = ratio\n",
    "    return ratios, log\n",
    "\n",
    "\n",
    "def plot_ratios(ratios):\n",
    "    if not ratios:\n",
    "        print(\"No valid ratios were calculated.\")\n",
    "        return\n",
    "\n",
    "    # Use quantiles to divide the ratios into 5 balanced categories\n",
    "    quantiles = np.quantile(ratios, [0, 0.3, 0.6, 1])\n",
    "    category_counts = np.histogram(ratios, bins=quantiles)[0]\n",
    "\n",
    "    # Create category labels\n",
    "    category_labels = []\n",
    "    for i in range(len(quantiles) - 1):\n",
    "        label = f\"{quantiles[i]:.2f}-{quantiles[i + 1]:.2f}\"\n",
    "        category_labels.append(label)\n",
    "\n",
    "    # Plot the distribution of ratios in 5 categories\n",
    "    plt.bar(category_labels, category_counts)\n",
    "    plt.xlabel('Speech Length to Token Ratio Categories')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Speech Length to Token Ratios in 5 Balanced Categories')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "def sameSpk_differentSpeed(speed_log, slow_threshold=0.3, fast_threshold=0.17):\n",
    "    \"\"\"\n",
    "    speed_log: {\n",
    "        wav_filename: speed_ratio\n",
    "    }\n",
    "    ->\n",
    "    {\n",
    "        spk_name: {\n",
    "            'slow': [wav_filename],\n",
    "            'fast': [wav_filename]\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    spk_dict = {}\n",
    "    for wav_filename, speed_ratio in speed_log.items():\n",
    "        spk_name = wav_filename.split('_')[0]\n",
    "        if spk_name not in spk_dict:\n",
    "            spk_dict[spk_name] = {\n",
    "                'slow': [],\n",
    "                'fast': [],\n",
    "                'medium': [],\n",
    "            }\n",
    "        if speed_ratio > slow_threshold:\n",
    "            spk_dict[spk_name]['slow'].append(wav_filename)\n",
    "        elif speed_ratio < fast_threshold:\n",
    "            spk_dict[spk_name]['fast'].append(wav_filename)\n",
    "        else:\n",
    "            spk_dict[spk_name]['medium'].append(wav_filename)\n",
    "    return spk_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get (wav_path, text caption) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125581/125581 [07:17<00:00, 286.93it/s]\n"
     ]
    }
   ],
   "source": [
    "path_list = []\n",
    "### Genshin/wav stores wav format audio files in 16khz\n",
    "# Genshin/metadata.csv stores the corresponding text captions in format of 'Name|caption'\n",
    "wav_folder = '/share5/users/jiachuan/data/llasa_ft_data/Genshin/wav'\n",
    "txt_csv = '/share5/users/jiachuan/data/llasa_ft_data/Genshin/metadata.csv'\n",
    "column_names = ['Name', 'caption']\n",
    "meta_df = pd.read_csv(txt_csv,header=None,sep='|',names=column_names)\n",
    "\n",
    "for wav_f in tqdm(os.listdir(wav_folder)[:]):\n",
    "    if not wav_f.endswith('.wav'):\n",
    "        continue\n",
    "    wav_path = os.path.join(wav_folder, wav_f)\n",
    "    query_name = wav_f.replace('.wav', '')\n",
    "    text_caption_result = meta_df.query(f\"Name == '{query_name}'\")\n",
    "    if not text_caption_result.empty:\n",
    "        text_caption = text_caption_result['caption'].values[0]\n",
    "        if len(text_caption.split()) > 5: # we only keep the audio with more than 5 words\n",
    "            path_list.append((wav_path, text_caption))\n",
    "\n",
    "# log = calculate_and_plot_ratios(path_list, tokenizer,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Sec Per Syllable for each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 41201/107406 [08:57<14:22, 76.72it/s]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# count the number of syllables for each audio sample\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sps_list, log \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_syllable_ratios\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 84\u001b[0m, in \u001b[0;36mcalculate_syllable_ratios\u001b[0;34m(path_list)\u001b[0m\n\u001b[1;32m     82\u001b[0m log \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wav_path, text_caption \u001b[38;5;129;01min\u001b[39;00m tqdm(path_list):\n\u001b[0;32m---> 84\u001b[0m     speech_length \u001b[38;5;241m=\u001b[39m \u001b[43mget_speech_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     syllable_count \u001b[38;5;241m=\u001b[39m count_syllables_in_transcript(text_caption)\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m speech_length \u001b[38;5;129;01mand\u001b[39;00m syllable_count:\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mget_speech_length\u001b[0;34m(wav_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_speech_length\u001b[39m(wav_path):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Load the audio file\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Convert the audio to 16-bit PCM format with a sample rate of 16000 Hz\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     audio \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mset_frame_rate(\u001b[38;5;241m16000\u001b[39m)\u001b[38;5;241m.\u001b[39mset_channels(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mset_sample_width(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/share5/users/jiachuan/code/envs/xcodec2/lib/python3.9/site-packages/pydub/audio_segment.py:808\u001b[0m, in \u001b[0;36mAudioSegment.from_wav\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_wav\u001b[39m(\u001b[38;5;28mcls\u001b[39m, file, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share5/users/jiachuan/code/envs/xcodec2/lib/python3.9/site-packages/pydub/audio_segment.py:651\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m file, close_file \u001b[38;5;241m=\u001b[39m \u001b[43m_fd_or_path_or_tempfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m:\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m/share5/users/jiachuan/code/envs/xcodec2/lib/python3.9/site-packages/pydub/utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     57\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fd, basestring):\n\u001b[0;32m---> 60\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     close_fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# count the number of syllables for each audio sample\n",
    "sps_list, log = calculate_syllable_ratios(path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only select speakers with more than 2 fast and slow pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_speed_dict = sameSpk_differentSpeed(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_spk = set()\n",
    "for spk in spk_speed_dict:\n",
    "    if len(spk_speed_dict[spk]['slow']) > 2 and len(spk_speed_dict[spk]['fast']) > 2:\n",
    "        valid_spk .add(spk)\n",
    "len(valid_spk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort and store  the selected pairs based on different speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### store valid speakers and corresponding audio files with different speed\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The stored folder structure is as follows:\n",
    "speaker_withDifferent_speed\n",
    "    spk1\n",
    "        slow.txt\n",
    "        fast.txt\n",
    "        medium.txt\n",
    "    spk2\n",
    "        ...\n",
    "\"\"\"\n",
    "\n",
    "speaker_withDifferent_speed_folder = '/share5/users/jiachuan/data/llasa_ft_data/Genshin/speaker_withDifferent_speed'\n",
    "\n",
    "if not os.path.exists(speaker_withDifferent_speed_folder):\n",
    "    os.makedirs(speaker_withDifferent_speed_folder)\n",
    "for spk in valid_spk:\n",
    "    spk_folder = os.path.join(speaker_withDifferent_speed_folder, spk)\n",
    "    if not os.path.exists(spk_folder):\n",
    "        os.makedirs(spk_folder)\n",
    "    for speed in ['slow', 'fast', 'medium']:\n",
    "        with open(os.path.join(spk_folder, f'{speed}.txt'), 'w') as f:\n",
    "            for wav_f in spk_speed_dict[spk][speed]:\n",
    "                f.write(wav_f + '\\n')\n",
    "         \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xcodec2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
